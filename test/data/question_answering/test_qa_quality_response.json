{
  "candidates": [
    {
      "content": {
        "role": "model",
        "parts": [
          {
            "text": "{\n\"rating\": \"5\",\n\"evaluation\": \"The AI response correctly identifies a question and answer from the provided document. The answer is accurate and the reasoning is sound and quotes the document verbatim.\"\n}\n"
          }
        ]
      },
      "finishReason": "STOP",
      "safetyRatings": [
        {
          "category": "HARM_CATEGORY_HATE_SPEECH",
          "probability": "NEGLIGIBLE",
          "probabilityScore": 0.034179688,
          "severity": "HARM_SEVERITY_NEGLIGIBLE",
          "severityScore": 0.111328125
        },
        {
          "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
          "probability": "NEGLIGIBLE",
          "probabilityScore": 0.103515625,
          "severity": "HARM_SEVERITY_NEGLIGIBLE",
          "severityScore": 0.068359375
        },
        {
          "category": "HARM_CATEGORY_HARASSMENT",
          "probability": "NEGLIGIBLE",
          "probabilityScore": 0.071777344,
          "severity": "HARM_SEVERITY_NEGLIGIBLE",
          "severityScore": 0.046142578
        },
        {
          "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
          "probability": "NEGLIGIBLE",
          "probabilityScore": 0.03173828,
          "severity": "HARM_SEVERITY_NEGLIGIBLE",
          "severityScore": 0.09033203
        }
      ],
      "avgLogprobs": -0.1950966093275282
    }
  ],
  "usageMetadata": {
    "promptTokenCount": 1286,
    "candidatesTokenCount": 45,
    "totalTokenCount": 1331
  }
}
